{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textatistic as tx\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import sklearn\n",
    "\n",
    "from threading import Thread\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   DATA CLEANING\n",
    "\n",
    "neg_data = []\n",
    "pos_data = []\n",
    "\n",
    "dir_neg = r\"C:\\Users\\KingED\\Documents\\Random\\NLP_init\\test\\neg\"\n",
    "dir_pos = r\"C:\\Users\\KingED\\Documents\\Random\\NLP_init\\test\\pos\"\n",
    "\n",
    "def maker(loc: list, path: str):\n",
    "    for files in os.listdir(path):\n",
    "        os.chdir(path)\n",
    "        with open(files, 'rb+') as file:\n",
    "            loc.append(file.readlines())\n",
    "       \n",
    "maker(neg_data, dir_neg)\n",
    "maker(pos_data, dir_pos)\n",
    "\n",
    "\n",
    "pattern_1 = r\"^b\\\"|^b\\'\"\n",
    "pattern_2 = r\"<br\\s\\/\\>\"\n",
    "patter_3 = r'\\\\|\\\"|\\''\n",
    "\n",
    "pos_word = []\n",
    "neg_word = []\n",
    "\n",
    "#FIXME : convert these loops into functions\n",
    "for c in pos_data:\n",
    "    word = str(c[0])\n",
    "    word = re.sub(pattern_2, \"\", word)\n",
    "    word = re.sub(pattern_1, \"\", word)\n",
    "    word = re.sub(patter_3, \"\", word)\n",
    "    pos_word.append(word)\n",
    "    \n",
    "for c in neg_data:\n",
    "    word = str(c[0])\n",
    "    word = re.sub(pattern_2, \"\", word)\n",
    "    word = re.sub(pattern_1, \"\", word)\n",
    "    word = re.sub(patter_3, \"\", word)\n",
    "    neg_word.append(word)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: make this function compute the gunningfog and flesch scores at the same time \n",
    "\n",
    "fog_scores = []\n",
    "flesch_score = []\n",
    "issues = []\n",
    "for x in pos_word:\n",
    "    try:\n",
    "        fog = tx.gunningfog_score(x)\n",
    "        flesch = tx.flesch_score(x)\n",
    "        fog_scores.append(fog)\n",
    "        flesch_score.append(flesch)\n",
    "      \n",
    "    except ZeroDivisionError:\n",
    "        issues.append(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average flesch score for poistive reviews is 78.17089281827614\n",
      "the average runningfog scores for the postive reviews is 9.868059804420177\n"
     ]
    }
   ],
   "source": [
    "average_fog = sum(fog_scores)/ len(fog_scores)\n",
    "average_flesch = sum(flesch_score)/ len(flesch_score)\n",
    "\n",
    "print(f\"the average flesch score for poistive reviews is {average_flesch}\")\n",
    "print(f\"the average runningfog scores for the postive reviews is {average_fog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>I was extraordinarily impressed by this film. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>Although Im not a golf fan, I attended a sneak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>From the start of The Edge Of Love, the viewer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>This movie, with all its complexity and subtle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>Ive seen this story before but my kids havent....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  score\n",
       "0      Once again Mr. Costner has dragged out a movie...      0\n",
       "1      This is an example of why the majority of acti...      0\n",
       "2      First of all I hate those moronic rappers, who...      0\n",
       "3      Not even the Beatles could write songs everyon...      0\n",
       "4      Brass pictures (movies is not a fitting word f...      0\n",
       "...                                                  ...    ...\n",
       "24995  I was extraordinarily impressed by this film. ...      1\n",
       "24996  Although Im not a golf fan, I attended a sneak...      1\n",
       "24997  From the start of The Edge Of Love, the viewer...      1\n",
       "24998  This movie, with all its complexity and subtle...      1\n",
       "24999  Ive seen this story before but my kids havent....      1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_pos = pd.DataFrame({'review': pos_word, 'score': 1})\n",
    "doc_neg = pd.DataFrame({'review': neg_word, 'score': 0})\n",
    "\n",
    "data  = pd.concat([doc_neg, doc_pos], ignore_index=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file aready exists\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r\"C:\\Users\\KingED\\Documents\\Random\\NLP_init\")\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file != 'review.csv':\n",
    "        data.to_csv('review.csv')\n",
    "    else:\n",
    "        print(\"file aready exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costners character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks hes better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutchers ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.',\n",
       "       0], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array = data.values\n",
    "data_array[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: TOKENIZATION\n",
    "TODO: REMOVE STOPWORDS\n",
    "TODO: LEMMATIZE\n",
    "TODO: WORD AND CHARACTER COUNT\n",
    "\n",
    "\"\"\"\n",
    "def token_maker(word: list) -> list:\n",
    "    words = []\n",
    "    for x in range(len(pos_word)):\n",
    "        words.append(word_tokenize(word[x]))\n",
    "    return words\n",
    "\n",
    "pos_tokens = token_maker(pos_word)\n",
    "neg_tokens = token_maker(neg_word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPACEY\n",
    "\"\"\"\n",
    "TODO: NER\n",
    "TODO: POS TAGGING\n",
    "\"\"\"\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# doc = nlp(doc)\n",
    "\n",
    "# def ner_pos():\n",
    "#     ners = [(token.text, token.label_) for word in doc]\n",
    "#     tags = [(token.text, token.tags_) for word in doc]\n",
    "    \n",
    "word = word_tokenize(pos_word[1])\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "tfid = TfidfVectorizer()\n",
    "\n",
    "# lemma.lemmatize(word)\n",
    "tfidword = tfid.fit_transform(data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KingED\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 'nt', 've'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17500, 68662)\n",
      "the accuracy of the model is: 87.14666666666666\n"
     ]
    }
   ],
   "source": [
    "counter = CountVectorizer(lowercase=True,\n",
    "                          strip_accents='ascii',\n",
    "                          tokenizer=None,\n",
    "                          stop_words=list(STOP_WORDS),\n",
    "                          )\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "data['score'] = encoder.fit_transform(data['score'])\n",
    "\n",
    "x = data['review'].values\n",
    "y = data['score'].values\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, shuffle=True, test_size=0.3, random_state=34)\n",
    "\n",
    "\n",
    "new_xtrain = counter.fit_transform(xtrain)\n",
    "new_xtest = counter.transform(xtest)\n",
    "\n",
    "print(new_xtrain.shape)\n",
    "\n",
    "model = MultinomialNB(alpha=1)\n",
    "model.fit(new_xtrain, ytrain)\n",
    "pred = model.predict(new_xtest)\n",
    "print(f\"the accuracy of the model is: {accuracy_score(pred, ytest) * 100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
